{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'camera_calibation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-28dfeb0a889e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcamera_calibation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcalibrate_camera\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mglobal\u001b[0m \u001b[0mcalibration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcalibration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalibrate_camera\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'camera_calibation'"
     ]
    }
   ],
   "source": [
    "from camera_calibation import calibrate_camera\n",
    "\n",
    "global calibration\n",
    "calibration = calibrate_camera()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count and save filenames of car and non-car image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vehicle images found: 8792\n",
      "Number of Non-vehicle images found: 8967\n",
      "Using: 8 orientations 8 pixels per cell and 2 cells per block and colorspace YCrCb\n",
      "Feature vector length: 5520\n",
      "5.92 Seconds to train SVC...\n",
      "Test Accuracy of SVC =  0.99\n"
     ]
    }
   ],
   "source": [
    "from train_classifier import get_trained_classifier\n",
    "svc, X_scaler = get_trained_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from line import Line\n",
    "\n",
    "def reset_globals():\n",
    "    left_line = Line()\n",
    "    right_line = Line()\n",
    "\n",
    "    global lines\n",
    "    lines = {\n",
    "        'left': left_line, \n",
    "        'right': right_line\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display samples of car and non-car HOG images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import lane_detection as ld\n",
    "import vehicle_detection as vd\n",
    "\n",
    "def pipeline(img):\n",
    "    global lines, calibration\n",
    "    \n",
    "    undistorted_img = ld.undistort(img, calibration[0], calibration[1])\n",
    "    size_for_warp = (int(undistorted_img.shape[1]/2), undistorted_img.shape[0])\n",
    "    M, M_inv = ld.get_warp_matrix(undistorted_img)\n",
    "    warped = cv2.warpPerspective(undistorted_img, M, size_for_warp, flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    thresholded_image = ld.threshold_image(warped)\n",
    "\n",
    "    left = ld.get_line_fit(thresholded_image, lines, 'left')\n",
    "    right = ld.get_line_fit(thresholded_image, lines, 'right')\n",
    "    \n",
    "    if ld.get_left_right_compliance(left, right) and left.detected:\n",
    "        left.update()\n",
    "\n",
    "    if ld.get_left_right_compliance(right, left) and right.detected:  \n",
    "        right.update()\n",
    "\n",
    "    overlayer = ld.get_overlayer(warped, lines)\n",
    "    size_for_unwarp = (int(undistorted_img.shape[1]), undistorted_img.shape[0])\n",
    "    unwarped = cv2.warpPerspective(overlayer, M_inv, size_for_unwarp, flags=cv2.INTER_LINEAR)\n",
    "    vehicles_detected = vd.detect_vehicles(undistorted_img, svc, X_scaler)\n",
    "    return ld.overlay_image(vehicles_detected, unwarped, lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_sample_output3.mp4\n",
      "[MoviePy] Writing video project_sample_output3.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 70/71 [00:44<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_sample_output3.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "reset_globals()\n",
    "project_output = 'project_sample_output3.mp4'\n",
    "clip = VideoFileClip(\"project_sample4.mp4\")\n",
    "test_clip = clip.fl_image(pipeline)\n",
    "test_clip.write_videofile(project_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "    <source src=\"project_sample_output3.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "    <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(project_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reset_globals()\n",
    "project_output = 'project_output.mp4'\n",
    "clip = VideoFileClip(\"project_video.mp4\")\n",
    "test_clip = clip.fl_image(pipeline)\n",
    "test_clip.write_videofile(project_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "    <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(project_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:sdc_env]",
   "language": "python",
   "name": "conda-env-sdc_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
